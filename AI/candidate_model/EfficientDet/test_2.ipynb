{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45544482",
   "metadata": {},
   "outputs": [],
   "source": [
    "# consider this is a simple dataset, train head will be enough.\n",
    "! python train.py -c 3 -p canary --lr 1e-3 --batch_size 28 --load_weights weights/efficientdet-d3.pth  --num_epochs 300 --save_interval 288 --head_only True\n",
    "\n",
    "# the loss will be high at first\n",
    "# don't panic, be patient,\n",
    "# just wait for a little bit longer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "950a29de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/batch/tasks/shared/LS_root/mounts/clusters/cksgh2/code/Users/cksgh1168/Yet-Another-EfficientDet-Pytorch\n"
     ]
    }
   ],
   "source": [
    "%cd Yet-Another-EfficientDet-Pytorch/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12139fd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.13s)\n",
      "creating index...\n",
      "index created!\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 6, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n",
      "loading annotations into memory...\n",
      "Done (t=0.03s)\n",
      "creating index...\n",
      "index created!\n",
      "[Warning] Ignoring Error(s) in loading state_dict for EfficientDetBackbone:\n",
      "\tsize mismatch for classifier.header.pointwise_conv.conv.weight: copying a param with shape torch.Size([810, 224, 1, 1]) from checkpoint, the shape in current model is torch.Size([144, 224, 1, 1]).\n",
      "\tsize mismatch for classifier.header.pointwise_conv.conv.bias: copying a param with shape torch.Size([810]) from checkpoint, the shape in current model is torch.Size([144]).\n",
      "[Warning] Don't panic if you see this, this might be because you load a pretrained weights with different number of classes. The rest of the weights should be loaded already.\n",
      "[Info] loaded weights: efficientdet-d4.pth, resuming checkpoint from step: 0\n",
      "  0%|                                                  | 0/4022 [00:00<?, ?it/s]/anaconda/envs/azureml_py36/lib/python3.6/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "Step: 4021. Epoch: 0/300. Iteration: 4022/4022. Cls loss: 0.77257. Reg loss: 3.1checkpoint...\n",
      "Step: 4021. Epoch: 0/300. Iteration: 4022/4022. Cls loss: 0.77257. Reg loss: 3.1\n",
      "Val. Epoch: 0/300. Classification loss: 1.64184. Regression loss: 3.59288. Total loss: 5.23473\n",
      "Step: 8043. Epoch: 1/300. Iteration: 4022/4022. Cls loss: 0.58201. Reg loss: 4.2checkpoint...\n",
      "Step: 8043. Epoch: 1/300. Iteration: 4022/4022. Cls loss: 0.58201. Reg loss: 4.2\n",
      "Val. Epoch: 1/300. Classification loss: 1.30786. Regression loss: 3.60421. Total loss: 4.91208\n",
      "Step: 12065. Epoch: 2/300. Iteration: 4022/4022. Cls loss: 0.54671. Reg loss: 2.checkpoint...\n",
      "Step: 12065. Epoch: 2/300. Iteration: 4022/4022. Cls loss: 0.54671. Reg loss: 2.\n",
      "Val. Epoch: 2/300. Classification loss: 1.17138. Regression loss: 3.01834. Total loss: 4.18972\n",
      "Step: 16087. Epoch: 3/300. Iteration: 4022/4022. Cls loss: 0.81352. Reg loss: 4.checkpoint...\n",
      "Step: 16087. Epoch: 3/300. Iteration: 4022/4022. Cls loss: 0.81352. Reg loss: 4.\n",
      "Val. Epoch: 3/300. Classification loss: 0.91182. Regression loss: 3.05115. Total loss: 3.96297\n",
      "Step: 20109. Epoch: 4/300. Iteration: 4022/4022. Cls loss: 0.36647. Reg loss: 2.checkpoint...\n",
      "Step: 20109. Epoch: 4/300. Iteration: 4022/4022. Cls loss: 0.36647. Reg loss: 2.\n",
      "Val. Epoch: 4/300. Classification loss: 0.76230. Regression loss: 3.25906. Total loss: 4.02137\n",
      "Step: 24131. Epoch: 5/300. Iteration: 4022/4022. Cls loss: 0.31912. Reg loss: 2.checkpoint...\n",
      "Step: 24131. Epoch: 5/300. Iteration: 4022/4022. Cls loss: 0.31912. Reg loss: 2.\n",
      "Val. Epoch: 5/300. Classification loss: 0.64389. Regression loss: 2.71217. Total loss: 3.35606\n",
      "Step: 28153. Epoch: 6/300. Iteration: 4022/4022. Cls loss: 0.33488. Reg loss: 1.checkpoint...\n",
      "Step: 28153. Epoch: 6/300. Iteration: 4022/4022. Cls loss: 0.33488. Reg loss: 1.\n",
      "Val. Epoch: 6/300. Classification loss: 0.67145. Regression loss: 2.78904. Total loss: 3.46049\n",
      "Step: 32175. Epoch: 7/300. Iteration: 4022/4022. Cls loss: 0.36698. Reg loss: 1.checkpoint...\n",
      "Step: 32175. Epoch: 7/300. Iteration: 4022/4022. Cls loss: 0.36698. Reg loss: 1.\n",
      "Val. Epoch: 7/300. Classification loss: 0.58629. Regression loss: 2.56316. Total loss: 3.14945\n",
      "Step: 36197. Epoch: 8/300. Iteration: 4022/4022. Cls loss: 0.30243. Reg loss: 2.checkpoint...\n",
      "Step: 36197. Epoch: 8/300. Iteration: 4022/4022. Cls loss: 0.30243. Reg loss: 2.\n",
      "Val. Epoch: 8/300. Classification loss: 0.62261. Regression loss: 2.61832. Total loss: 3.24092\n",
      "Step: 40219. Epoch: 9/300. Iteration: 4022/4022. Cls loss: 0.44513. Reg loss: 1.checkpoint...\n",
      "Step: 40219. Epoch: 9/300. Iteration: 4022/4022. Cls loss: 0.44513. Reg loss: 1.\n",
      "Val. Epoch: 9/300. Classification loss: 0.56204. Regression loss: 2.49474. Total loss: 3.05678\n",
      "Step: 44241. Epoch: 10/300. Iteration: 4022/4022. Cls loss: 0.38847. Reg loss: 0checkpoint...\n",
      "Step: 44241. Epoch: 10/300. Iteration: 4022/4022. Cls loss: 0.38847. Reg loss: 0\n",
      "Val. Epoch: 10/300. Classification loss: 0.54366. Regression loss: 2.36427. Total loss: 2.90794\n",
      "Step: 48263. Epoch: 11/300. Iteration: 4022/4022. Cls loss: 0.38815. Reg loss: 1checkpoint...\n",
      "Step: 48263. Epoch: 11/300. Iteration: 4022/4022. Cls loss: 0.38815. Reg loss: 1\n",
      "Val. Epoch: 11/300. Classification loss: 0.56647. Regression loss: 2.28849. Total loss: 2.85496\n",
      "Step: 52285. Epoch: 12/300. Iteration: 4022/4022. Cls loss: 0.26428. Reg loss: 1checkpoint...\n",
      "Step: 52285. Epoch: 12/300. Iteration: 4022/4022. Cls loss: 0.26428. Reg loss: 1\n",
      "Val. Epoch: 12/300. Classification loss: 0.55647. Regression loss: 2.23726. Total loss: 2.79373\n",
      "Step: 56307. Epoch: 13/300. Iteration: 4022/4022. Cls loss: 0.40067. Reg loss: 2checkpoint...\n",
      "Step: 56307. Epoch: 13/300. Iteration: 4022/4022. Cls loss: 0.40067. Reg loss: 2\n",
      "Val. Epoch: 13/300. Classification loss: 0.53192. Regression loss: 2.28541. Total loss: 2.81733\n",
      "Step: 60329. Epoch: 14/300. Iteration: 4022/4022. Cls loss: 0.15822. Reg loss: 0checkpoint...\n",
      "Step: 60329. Epoch: 14/300. Iteration: 4022/4022. Cls loss: 0.15822. Reg loss: 0\n",
      "Val. Epoch: 14/300. Classification loss: 0.50437. Regression loss: 2.19765. Total loss: 2.70202\n",
      "Step: 64351. Epoch: 15/300. Iteration: 4022/4022. Cls loss: 0.41245. Reg loss: 2checkpoint...\n",
      "Step: 64351. Epoch: 15/300. Iteration: 4022/4022. Cls loss: 0.41245. Reg loss: 2\n",
      "Val. Epoch: 15/300. Classification loss: 0.60015. Regression loss: 2.43091. Total loss: 3.03106\n",
      "Step: 68373. Epoch: 16/300. Iteration: 4022/4022. Cls loss: 0.30401. Reg loss: 0checkpoint...\n",
      "Step: 68373. Epoch: 16/300. Iteration: 4022/4022. Cls loss: 0.30401. Reg loss: 0\n",
      "Val. Epoch: 16/300. Classification loss: 0.60020. Regression loss: 2.46540. Total loss: 3.06560\n",
      "Step: 72395. Epoch: 17/300. Iteration: 4022/4022. Cls loss: 0.22074. Reg loss: 0checkpoint...\n",
      "Step: 72395. Epoch: 17/300. Iteration: 4022/4022. Cls loss: 0.22074. Reg loss: 0\n",
      "Val. Epoch: 17/300. Classification loss: 0.54154. Regression loss: 2.18141. Total loss: 2.72295\n",
      "Step: 76417. Epoch: 18/300. Iteration: 4022/4022. Cls loss: 0.26823. Reg loss: 1checkpoint...\n",
      "Step: 76417. Epoch: 18/300. Iteration: 4022/4022. Cls loss: 0.26823. Reg loss: 1\n",
      "Val. Epoch: 18/300. Classification loss: 0.50571. Regression loss: 2.18628. Total loss: 2.69199\n",
      "Step: 80439. Epoch: 19/300. Iteration: 4022/4022. Cls loss: 0.27048. Reg loss: 2checkpoint...\n",
      "Step: 80439. Epoch: 19/300. Iteration: 4022/4022. Cls loss: 0.27048. Reg loss: 2\n",
      "Val. Epoch: 19/300. Classification loss: 0.51197. Regression loss: 2.22344. Total loss: 2.73542\n",
      "Step: 84461. Epoch: 20/300. Iteration: 4022/4022. Cls loss: 0.62972. Reg loss: 2checkpoint...\n",
      "Step: 84461. Epoch: 20/300. Iteration: 4022/4022. Cls loss: 0.62972. Reg loss: 2\n",
      "Val. Epoch: 20/300. Classification loss: 0.50475. Regression loss: 2.20149. Total loss: 2.70624\n",
      "Step: 88483. Epoch: 21/300. Iteration: 4022/4022. Cls loss: 0.16216. Reg loss: 1checkpoint...\n",
      "Step: 88483. Epoch: 21/300. Iteration: 4022/4022. Cls loss: 0.16216. Reg loss: 1\n",
      "Val. Epoch: 21/300. Classification loss: 0.53282. Regression loss: 2.25266. Total loss: 2.78548\n",
      "Step: 92505. Epoch: 22/300. Iteration: 4022/4022. Cls loss: 0.55818. Reg loss: 2checkpoint...\n",
      "Step: 92505. Epoch: 22/300. Iteration: 4022/4022. Cls loss: 0.55818. Reg loss: 2\n",
      "Val. Epoch: 22/300. Classification loss: 0.49079. Regression loss: 2.13693. Total loss: 2.62772\n",
      "Step: 96527. Epoch: 23/300. Iteration: 4022/4022. Cls loss: 0.08723. Reg loss: 0checkpoint...\n",
      "Step: 96527. Epoch: 23/300. Iteration: 4022/4022. Cls loss: 0.08723. Reg loss: 0\n",
      "Val. Epoch: 23/300. Classification loss: 0.50718. Regression loss: 2.19826. Total loss: 2.70544\n",
      "Step: 100549. Epoch: 24/300. Iteration: 4022/4022. Cls loss: 0.11833. Reg loss: checkpoint...\n",
      "Step: 100549. Epoch: 24/300. Iteration: 4022/4022. Cls loss: 0.11833. Reg loss: \n",
      "Val. Epoch: 24/300. Classification loss: 0.51291. Regression loss: 2.15672. Total loss: 2.66962\n",
      "Step: 104571. Epoch: 25/300. Iteration: 4022/4022. Cls loss: 0.15596. Reg loss: checkpoint...\n",
      "Step: 104571. Epoch: 25/300. Iteration: 4022/4022. Cls loss: 0.15596. Reg loss: \n",
      "Val. Epoch: 25/300. Classification loss: 0.53532. Regression loss: 2.21929. Total loss: 2.75461\n",
      "Step: 108593. Epoch: 26/300. Iteration: 4022/4022. Cls loss: 0.23099. Reg loss: checkpoint...\n",
      "Step: 108593. Epoch: 26/300. Iteration: 4022/4022. Cls loss: 0.23099. Reg loss: \n",
      "Val. Epoch: 26/300. Classification loss: 0.51125. Regression loss: 2.25971. Total loss: 2.77096\n",
      "Step: 109452. Epoch: 27/300. Iteration: 859/4022. Cls loss: 0.21761. Reg loss: 0"
     ]
    }
   ],
   "source": [
    "# consider this is a simple dataset, train head will be enough.\n",
    "! python train.py -c 4 -p canary --lr 1e-3 --batch_size 2 --load_weights weights/efficientdet-d4.pth  --num_epochs 300 --save_interval 4022 --log_path 'logs_no_headonly/'\n",
    "# the loss will be high at first\n",
    "# don't panic, be patient,\n",
    "# just wait for a littlebit longer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4064468e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 - PyTorch",
   "language": "python",
   "name": "azureml_py38_pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
